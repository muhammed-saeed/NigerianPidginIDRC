{"input": "/PATH_TO/PLM4MT/data/textFiles/BibleJw300TreeBankShuffled.pcm2en", "output": "/PATH_TO/PLM4MT/checkpoints/PCM2En", "model": "mgpt_msp", "vocab": ["", ""], "pad": "<pad>", "bos": "<eos>", "eos": "<eos>", "unk": "<unk>", "batch_size": 4096, "fixed_batch_size": false, "min_length": 1, "max_length": 256, "buffer_size": 10000, "initializer_gain": 1.0, "initializer": "uniform_unit_scaling", "scale_l1": 0.0, "scale_l2": 0.0, "loss_scale": 128, "initial_step": 0, "warmup_steps": 4000, "train_steps": 100000, "update_cycle": 1, "optimizer": "Adam", "adam_beta1": 0.9, "adam_beta2": 0.98, "adam_epsilon": 1e-09, "adadelta_rho": 0.95, "adadelta_epsilon": 1e-07, "pattern": "", "clipping": "global_norm", "clip_grad_norm": 0.0, "initial_learning_rate": 1e-07, "learning_rate": 0.0007, "learning_rate_schedule": "linear_warmup_rsqrt_decay", "learning_rate_boundaries": [0], "learning_rate_values": [0.0], "device_list": ["[", "1", ",", "2", ",", "3", "]"], "keep_checkpoint_max": 20, "keep_top_checkpoint_max": 5, "save_summary": false, "save_checkpoint_secs": 0, "save_checkpoint_steps": 1000, "eval_steps": 2000, "eval_secs": 0, "top_beams": 1, "beam_size": 4, "decode_batch_size": 32, "decode_alpha": 0.6, "decode_ratio": 1.0, "decode_length": 50, "validation": "", "references": "", "prompt_length": 128, "label_smoothing": 0.1, "sep_id": 250099, "dec_no_prefix": false, "share_prompt": false, "re_encoding": 1}